RAG-агент (ИИ-ассистент для студентов медицинских вузов)
О проекте
Врач — та профессия, которая была и остается одной из наиболее значимых и важных для любого общества, но перед тем, как стать врачом нужно отучиться в медицинском вузе. А это задача не из простых: долгая учеба, непонятная терминология, целая куча предметов и гора сложных учебников, каждый из которых толщиной в кирпич.

Немногие справляются с такой нагрузкой, ко всему прочему, по собранной нами статистике, каждый третий студент-медик тратит на поиск информации более 10 минут (!), а также более 50% опрощенных ищут информацию в интернете. Это приводит нас к двум проблемам: время, потраченное на поиск информации, можно было бы эффективно перераспределить на другие важные задачи; более того, информация, добытая из интернета, не всегда является достоверной. И с решением этих проблем может справиться наш ИИ-помощник, основанный на RAG-системе.

ИИ-помощник предназначен для студентов-медицинских вузов — он позволяет искать информацию из релевантных источников, таких как: медицинские учебники, статьи и научные сайты. Также студент может сам подгрузить выбранный им файл. Теперь вместо 15 минут, студент будет тратить на поиски ответа всего одну минуту, избегая копаний в тонне книг.

Наша основная цель состоит в помощи именно СТУДЕНТАМ-медикам, поэтому даже если ИИ-помощник допустит ошибку, студент может всегда проконсультироваться с преподавателем. Но вероятность ошибки крайне мала, так как по мнению самих студентов модель выдаёт ответы, приближенные к информации из учебников, с точностью до 95%.

Вид агента:
image

Устройство модели:
Llama3.2 - главная LLM-модель, на которой построен агент
intfloat/multilingual-e5-base (for embeddings)
Tavily - сервис для выхода модели в WebSearch - получение API-ключа и выход в web
Langchain - фреймворк для работы с LLM-моделями.
LangGraph для описания текущих состояний модели - фреймворк для оркестровки агентных систем.
Архитектура модели:
Агент обладает сложной структурой обработки текста и генерации.

Фактически он состоит из двух частей - одна отвечает за обработку PDF-файлов, добавляемых пользователем, после чего создает FAISS-индексы, чтобы хранить все данные в виде векторного хранилища.

Вторая часть отвечает за саму RAG-систему - сначала на вход подается запрос пользователя. Если он не связан с медициной, то включается WebSearch. Если он связан с медицинской тематикой, то запускается retriever на основе векторного хранилища, созданного первой частью модели. Далее ретривер старается найти 3 релевантных отрывка. Если он находит хотя бы 1 подходящий отрывок, то генерация запускается. Иначе снова отправляется в Websearch. Затем генерация проверяется на галлюцинации и совпадение вопроса с ответом. В случае, если что-то не так, модель самокорректируется - на это ей дано 3 попытки.

Итого RAG обладает несколькими свойствами:

Самокоррекция
Маршрутизация
Самооценка
IMG_9517

Локальный запуск модели на своем железе
Для того, чтобы запустить агента, будет необходимо совершить несколько несложных действий.

Скачать Ollama на ПК по ссылке - https://ollama.com/download/windows (windows 10+ версия)

Открыть приложение Ollama и написать ollama pull llama3.2:3b-instruct-fp16 в специальной командной строке. На этом этапе вы скачиваете llama3.2 на 3 миллиарда параметров.

На всякий случай проверить, скачалась ли модель - ollama list 

Перед выполнением кода обязательно запускаем модель -  ollama run llama3.2 - теперь модель готова работать!

Переходим к коду - открыть:

main.py - если хотите запустить модель без streamlit.
main.py + Agent.py + страницы из папки pages - если хотите запустить модель через streamlit
Использование модели без streamlit:

(1.1) Если хотите использовать уже существующую базу знаний о медицине, то расскоментируйте последние 4 строчки кода и вставьте свой вопрос:

 ```  if __name__ == "__main__":
      inputs = {"question": "Что такое нейрон?", "max_retries": 3}
      for event in graph.stream(inputs, stream_mode="values"):
         logger.debug(event) ```
(1.2) Если хотите протестировать модель на своей литературе, то добавьте свой PDF-файл в папку /pdf/new . Затем вернитесь к пункту (1.1) и запишите свой вопрос. Запустите код. Ваш файл будет обработан как новый источник, и модель добавит его в векторное хранилище. Затем модель выдаст ответ.

Использование модели с streamlit:

(2.1) Откройте оба файла, пропишите в командной строке streamlit run Agent.py - перед вами откроется приложение. Если зададите вопрос в текстовой строке, то ответ будет сгенерирован на основе имеющейся базы знаний. Если загрузите в окошко слева свой PDF-файл, то он будет также добавлен в базу знаний. Далее модель выдает ответ пользователю.

Пример использования:

image

Пример использования модели на основе WebSearch:

image

(2.2) Ради интереса можете посетить и другие страницы сайта - в них содержится информация о модели, статистика (инфографика) из опроса студентов медицинских вузов и общая информация о проекте.

Другие элементы сайта
About project:
image

Statistics:
image

About model:
image
