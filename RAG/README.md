# RAG-агент (ИИ-ассистент для студентов медицинских вузов)
## О проекте
Врач — та профессия, которая была и остается одной из наиболее значимых и важных для любого общества, но перед тем, как стать врачом нужно отучиться в медицинском вузе. А это задача не из простых: долгая учеба, непонятная терминология, целая куча предметов и гора сложных учебников, каждый из которых толщиной в кирпич.

Немногие справляются с такой нагрузкой, ко всему прочему, по собранной нами статистике, *каждый третий студент-медик тратит на поиск информации более 10 минут (!)*, а также более 50% опрощенных ищут информацию в интернете. Это приводит нас к двум проблемам: время, потраченное на поиск информации, можно было бы эффективно перераспределить на другие важные задачи; более того, информация, добытая из интернета, не всегда является достоверной. И с решением этих проблем может справиться наш ИИ-помощник, основанный на RAG-системе.

ИИ-помощник предназначен для студентов-медицинских вузов — он позволяет искать информацию из релевантных источников, таких как: *медицинские учебники, статьи и научные сайты*. Также студент может сам подгрузить выбранный им файл. Теперь вместо 15 минут, студент будет тратить на поиски ответа всего одну минуту, избегая копаний в тонне книг.

Наша основная цель состоит в помощи именно *СТУДЕНТАМ-медикам*, поэтому даже если ИИ-помощник допустит ошибку, студент может всегда проконсультироваться с преподавателем. Но вероятность ошибки крайне мала, так как по мнению самих студентов модель выдаёт ответы, приближенные к информации из учебников, с точностью до 95%.

## Вид агента:
<img width="1741" height="922" alt="image" src="https://github.com/user-attachments/assets/15321c5f-694b-4b49-886a-3fc87bb72cba" />


## Устройство модели:
- Llama3.2 - главная LLM-модель, на которой построен агент
- intfloat/multilingual-e5-base (for embeddings)
- Tavily - сервис для выхода модели в WebSearch - получение API-ключа и выход в web
- Langchain - фреймворк для работы с LLM-моделями.
- LangGraph для описания текущих состояний модели - фреймворк для оркестровки агентных систем.
## Архитектура модели:
Агент обладает сложной структурой обработки текста и генерации.

Фактически он состоит из двух частей - одна отвечает за обработку PDF-файлов, добавляемых пользователем, после чего создает FAISS-индексы, чтобы хранить все данные в виде векторного хранилища.

Вторая часть отвечает за саму RAG-систему - сначала на вход подается запрос пользователя. Если он не связан с медициной, то включается WebSearch. Если он связан с медицинской тематикой, то запускается retriever на основе векторного хранилища, созданного первой частью модели. Далее ретривер старается найти 3 релевантных отрывка. Если он находит хотя бы 1 подходящий отрывок, то генерация запускается. Иначе снова отправляется в Websearch. Затем генерация проверяется на галлюцинации и совпадение вопроса с ответом. В случае, если что-то не так, модель самокорректируется - на это ей дано 3 попытки.

Итого RAG обладает несколькими свойствами:

- Самокоррекция
- Маршрутизация
- Самооценка
<img width="1920" height="780" alt="image" src="https://github.com/user-attachments/assets/e2617933-c266-4f9c-b0bc-40753e489cab" />


## Локальный запуск модели на своем железе
Для того, чтобы запустить агента, будет необходимо совершить несколько несложных действий

1. Скачать Ollama на ПК по ссылке - https://ollama.com/download/windows (windows 10+ версия)

2. Открыть приложение Ollama и написать ollama pull llama3.2:3b-instruct-fp16 в специальной командной строке. На этом этапе вы скачиваете llama3.2 на 3 миллиарда параметров.

3. На всякий случай проверить, скачалась ли модель - ollama list 

4. Перед выполнением кода обязательно запускаем модель -  ollama run llama3.2 - теперь модель готова работать!

5. Переходим к коду - открыть:

i. main.py - если хотите запустить модель без streamlit.
ii. main.py + Agent.py + страницы из папки pages - если хотите запустить модель через streamlit
1. Использование модели без streamlit:

(1.1) Если хотите использовать уже существующую базу знаний о медицине, то расскоментируйте последние 4 строчки кода и вставьте свой вопрос:

 ```if __name__ == "__main__": \ inputs = {"question": "Что такое нейрон?", "max_retries": 3} \ for event in graph.stream(inputs, stream_mode="values"):\ logger.debug(event)``` 

(1.2) Если хотите протестировать модель на своей литературе, то добавьте свой PDF-файл в папку /pdf/new . Затем вернитесь к пункту (1.1) и запишите свой вопрос. Запустите код. Ваш файл будет обработан как новый источник, и модель добавит его в векторное хранилище. Затем модель выдаст ответ.

2. Использование модели с streamlit:

(2.1) Откройте оба файла, пропишите в командной строке streamlit run Agent.py - перед вами откроется приложение. Если зададите вопрос в текстовой строке, то ответ будет сгенерирован на основе имеющейся базы знаний. Если загрузите в окошко слева свой PDF-файл, то он будет также добавлен в базу знаний. Далее модель выдает ответ пользователю.

*Пример использования:*

<img width="870" height="336" alt="image" src="https://github.com/user-attachments/assets/3541060d-6bf6-462d-a0ec-fd4930627b67" />


*Пример использования модели на основе WebSearch:*

<img width="832" height="177" alt="image" src="https://github.com/user-attachments/assets/34754d58-78ad-46ff-b987-f08f58683f0b" />


(2.2) Ради интереса можете посетить и другие страницы сайта - в них содержится информация о модели, статистика (инфографика) из опроса студентов медицинских вузов и общая информация о проекте.

## Другие элементы сайта
### About project:
<img width="1723" height="929" alt="image" src="https://github.com/user-attachments/assets/02aa5988-28d9-44d8-bc9e-12ce6e172ad6" />


### Statistics:
<img width="1728" height="930" alt="image" src="https://github.com/user-attachments/assets/e76546f8-031a-40d3-9e4e-ded65fbc42f6" />


### About model:
<img width="1725" height="926" alt="image" src="https://github.com/user-attachments/assets/4f820169-566a-437a-9910-5cc19bf6d6cc" />

